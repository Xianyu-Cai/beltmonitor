"""
Windows CUDAä¼˜åŒ–ç‰ˆæ£€æµ‹è„šæœ¬
åŸºäºåŸå§‹detect-cap-1.pyè¿›è¡ŒCUDAä¼˜åŒ–
"""
import warnings
warnings.filterwarnings('ignore')

import argparse
import os
import cv2
import subprocess
import threading
import time
import queue
import json
import numpy as np
from pathlib import Path
import torch
import psutil

# å¯¼å…¥åŸå§‹æ¨¡å—
from ultralytics import YOLO
from config_manager import config_manager
from alarm_type_mapper import AlarmTypeMapper
from event_reporter import EventReporter
from modbus_client import ModbusClient
from ws_producer import detection_producer

class CudaOptimizedDetector:
    def __init__(self, camera_id=None):
        self.camera_id = camera_id
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.cuda_available = torch.cuda.is_available()
        
        if self.cuda_available:
            print(f"ğŸš€ CUDAå¯ç”¨: {torch.cuda.get_device_name(0)}")
            torch.cuda.empty_cache()
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
        else:
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
    
    def optimize_video_capture(self, rtsp_url: str) -> cv2.VideoCapture:
        """ä¼˜åŒ–è§†é¢‘æ•è·"""
        print("ğŸ“¹ ä¼˜åŒ–è§†é¢‘æ•è·...")
        
        # å°è¯•FFmpegåç«¯
        cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
        if not cap.isOpened():
            cap = cv2.VideoCapture(rtsp_url)
        
        if cap.isOpened():
            # ä¼˜åŒ–ç¼“å†²åŒºè®¾ç½®
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)
            cap.set(cv2.CAP_PROP_FPS, 15)  # é™ä½FPS
            
            # è·å–å®é™…å‚æ•°
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            print(f"ğŸ“Š è§†é¢‘å‚æ•°: {width}x{height}@{fps}fps")
            
        return cap
    
    def optimize_model(self, model_path: str) -> YOLO:
        """ä¼˜åŒ–YOLOæ¨¡å‹"""
        print("ğŸ§  ä¼˜åŒ–YOLOæ¨¡å‹...")
        
        model = YOLO(model_path)
        
        if self.cuda_available:
            # ç§»åŠ¨åˆ°GPU
            model.model.to(self.device)
            # åŠç²¾åº¦ä¼˜åŒ–
            model.model.half()
            print("âœ… æ¨¡å‹å·²ä¼˜åŒ–ä¸ºCUDA+FP16")
        else:
            print("âš ï¸ ä½¿ç”¨æ ‡å‡†CPUæ¨¡å‹")
            
        return model
    
    def create_optimized_ffmpeg(self, width: int, height: int, fps: int, camera_id: int = None) -> Tuple[subprocess.Popen, str]:
        """åˆ›å»ºä¼˜åŒ–çš„FFmpegè¿›ç¨‹"""
        output_dir = 'hls_output'
        os.makedirs(output_dir, exist_ok=True)
        
        if camera_id:
            camera_dir = os.path.join(output_dir, f'camera_{camera_id}')
            os.makedirs(camera_dir, exist_ok=True)
            output_path = os.path.join(camera_dir, 'output.m3u8')
            hls_url = f"http://localhost:{2000 + camera_id}/hls_output/camera_{camera_id}/output.m3u8"
        else:
            output_path = os.path.join(output_dir, 'output.m3u8')
            hls_url = "http://localhost:2022/hls_output/output.m3u8"
        
        # ä¼˜åŒ–FFmpegå‘½ä»¤
        command = [
            'ffmpeg', '-y',
            '-f', 'rawvideo',
            '-vcodec', 'rawvideo',
            '-pix_fmt', 'bgr24',
            '-s', f'{width}x{height}',
            '-r', str(fps),
            '-i', '-',
            '-c:v', 'h264_nvenc',  # NVIDIAç¡¬ä»¶ç¼–ç 
            '-preset', 'fast',
            '-pix_fmt', 'yuv420p',
            '-f', 'hls',
            '-hls_time', '2',
            '-hls_list_size', '5',
            '-hls_flags', 'delete_segments',
            output_path
        ]
        
        process = subprocess.Popen(command, stdin=subprocess.PIPE)
        return process, hls_url
    
    def monitor_performance(self):
        """æ€§èƒ½ç›‘æ§å™¨"""
        def monitor():
            while True:
                if self.cuda_available:
                    gpu_util = torch.cuda.utilization()
                    memory_used = torch.cuda.memory_allocated() / 1024**3
                    print(f"ğŸ“ˆ GPU: {gpu_util}% | æ˜¾å­˜: {memory_used:.2f}GB")
                
                # ç³»ç»Ÿä¿¡æ¯
                cpu_percent = psutil.cpu_percent()
                memory = psutil.virtual_memory()
                print(f"ğŸ’» CPU: {cpu_percent}% | å†…å­˜: {memory.percent}%")
                
                time.sleep(10)
        
        monitor_thread = threading.Thread(target=monitor, daemon=True)
        monitor_thread.start()
    
    def cuda_predict_realtime(self, model_path: str, rtsp_url: str, **kwargs):
        """CUDAä¼˜åŒ–çš„å®æ—¶é¢„æµ‹"""
        print("ğŸ¯ å¯åŠ¨CUDAä¼˜åŒ–æ£€æµ‹...")
        
        # ä¼˜åŒ–è§†é¢‘æ•è·
        cap = self.optimize_video_capture(rtsp_url)
        if not cap.isOpened():
            raise IOError(f"æ— æ³•æ‰“å¼€è§†é¢‘æµ: {rtsp_url}")
        
        # ä¼˜åŒ–æ¨¡å‹
        model = self.optimize_model(model_path)
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        self.monitor_performance()
        
        # è®¾ç½®ç›®æ ‡åˆ†è¾¨ç‡
        target_width = 640
        target_height = 360
        fps = 15
        
        # ä¼˜åŒ–FFmpeg
        ffmpeg_process, hls_url = self.create_optimized_ffmpeg(
            target_width, target_height, fps, self.camera_id
        )
        
        # æ›´æ–°æ•°æ®åº“
        if self.camera_id:
            from config_manager import config_manager
            config_manager.update_camera_hls_url(self.camera_id, hls_url)
        
        frame_count = 0
        last_detection_time = 0
        detection_interval = kwargs.get('detection_interval', 0.5)
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                current_time = time.time()
                
                # æ™ºèƒ½é‡‡æ ·ï¼šåªåœ¨æ—¶é—´é—´éš”åˆ°è¾¾æ—¶æ£€æµ‹
                if current_time - last_detection_time >= detection_interval:
                    # è°ƒæ•´å¤§å°
                    frame_resized = cv2.resize(frame, (target_width, target_height))
                    
                    if self.cuda_available:
                        # CUDAåŠ é€Ÿæ¨ç†
                        frame_tensor = torch.from_numpy(frame_resized).to(self.device)
                        frame_tensor = frame_tensor.half()
                    
                    # YOLOæ£€æµ‹
                    results = model.predict(
                        source=frame_resized,
                        imgsz=640,
                        conf=kwargs.get('conf', 0.25),
                        device=self.device,
                        half=self.cuda_available,
                        save=False,
                        verbose=False
                    )
                    
                    # å¤„ç†ç»“æœ...
                    self.process_results(results, frame_resized)
                    
                    last_detection_time = current_time
                
                # å‘é€å¸§åˆ°FFmpeg
                if ffmpeg_process.stdin:
                    try:
                        ffmpeg_process.stdin.write(frame.tobytes())
                        ffmpeg_process.stdin.flush()
                    except BrokenPipeError:
                        print("âŒ FFmpegç®¡é“å·²æŸå")
                        break
                
                if frame_count % 30 == 0:
                    print(f"ğŸ“Š å·²å¤„ç† {frame_count} å¸§")
        
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ£€æµ‹")
        
        finally:
            cap.release()
            if ffmpeg_process.stdin:
                ffmpeg_process.stdin.close()
            ffmpeg_process.wait()
            
            if self.cuda_available:
                torch.cuda.empty_cache()
    
    def process_results(self, results, frame):
        """å¤„ç†æ£€æµ‹ç»“æœ"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªå®šä¹‰çš„å¤„ç†é€»è¾‘
        pass

def create_cuda_launch_script():
    """åˆ›å»ºCUDAå¯åŠ¨è„šæœ¬"""
    script_content = """@echo off
echo Windows CUDAä¼˜åŒ–æ£€æµ‹å¯åŠ¨å™¨
echo.

REM æ£€æŸ¥CUDA
python -c "import torch; print('CUDAå¯ç”¨:', torch.cuda.is_available())"

REM è®¾ç½®ä¼˜åŒ–ç¯å¢ƒ
set CUDA_VISIBLE_DEVICES=0
set PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

echo.
echo å¯åŠ¨ä¼˜åŒ–æ£€æµ‹...
python detect_cuda_optimized.py --model best.pt --source rtsp://your_camera_url --cameraid 1 --detection-interval 0.5

pause
"""
    
    with open('start_cuda_optimized.bat', 'w') as f:
        f.write(script_content)
    
    print("âœ… å·²åˆ›å»ºå¯åŠ¨è„šæœ¬: start_cuda_optimized.bat")

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Windows CUDAä¼˜åŒ–æ£€æµ‹')
    parser.add_argument('--model', required=True, help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--source', required=True, help='è§†é¢‘æºURL')
    parser.add_argument('--cameraid', type=int, help='æ‘„åƒå¤´ID')
    parser.add_argument('--detection-interval', type=float, default=0.5, help='æ£€æµ‹é—´éš”(ç§’)')
    parser.add_argument('--conf', type=float, default=0.25, help='ç½®ä¿¡åº¦é˜ˆå€¼')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        print("ğŸ‰ CUDAç¯å¢ƒå·²å°±ç»ªï¼")
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    else:
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUä¼˜åŒ–")
    
    # å¯åŠ¨æ£€æµ‹
    detector = CudaOptimizedDetector(args.cameraid)
    detector.cuda_predict_realtime(
        model_path=args.model,
        rtsp_url=args.source,
        detection_interval=args.detection_interval,
        conf=args.conf
    )